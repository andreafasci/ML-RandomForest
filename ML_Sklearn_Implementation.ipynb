{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful stuff from libraries etc\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from file into a dataframe\n",
    "df = pd.read_csv('processed.cleveland.data', header=None)\n",
    "\n",
    "# Assign the names of the column to the corresponding data\n",
    "df.columns = ['age','sex','cp', 'trestbps','chol','fbs', 'restecg', 'thalach','exang','oldpeak','slope','ca','thal','num']\n",
    "df = df.astype({'age': int, 'sex': int, 'cp': int, 'trestbps': int, 'chol': int, 'fbs': int, 'restecg': int, 'thalach':int, 'exang': int, 'slope': int, 'ca':int, 'thal':int})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <br> <b>Description of features: </b>\n",
    "    <br> Age = age in years \n",
    "    <br> Sex = sex (0 = female; 1 = male)\n",
    "    <br> cp = chest pain type\n",
    "        <br> &nbsp; -- Value 1: typical angina\n",
    "        <br> &nbsp; -- Value 2: atypical angina\n",
    "        <br> &nbsp; -- Value 3: non-anginal pain\n",
    "        <br> &nbsp; -- Value 4: asymptomatic\n",
    "    <br> trestbps = resting blood pressure (in mm Hg on admission to the hospital)\n",
    "    <br> chol = serum cholestoral in mg/dl\n",
    "    <br> fbs = (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n",
    "    <br> restecg = resting electrocardiographic results\n",
    "        <br> &nbsp; -- Value 0: normal\n",
    "        <br> &nbsp; -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "        <br> &nbsp; -- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "    <br> thalach = maximum heart rate achieved\n",
    "    <br> exang = exercise induced angina (1 = yes; 0 = no)\n",
    "    <br> oldpeak = ST depression induced by exercise relative to rest\n",
    "    <br> slope = the slope of the peak exercise ST segment\n",
    "        <br> &nbsp;-- Value 1: upsloping\n",
    "        <br> &nbsp;-- Value 2: flat\n",
    "        <br> &nbsp;-- Value 3: downsloping\n",
    "    <br> ca = number of major vessels (0-3) colored by flourosopy\n",
    "    <br> thal = ?\n",
    "        <br> &nbsp;-- 3 = normal\n",
    "        <br> &nbsp;-- 6 = fixed defect\n",
    "        <br> &nbsp;-- 7 = reversable defect\n",
    "    <br> num = (0 = absence; 1,2,3,4 = presence)\n",
    "    \n",
    "    <hr>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    Some features have categorical data...in order to pass from categorical data to non-categorical data <br>\n",
    "    I will apply <i>One Hot Encoding</i> <br><br>\n",
    "    Features before: <br>\n",
    "    <b>age</b>, <b>sex</b>, cp, <b>trestbps</b>, <b>chol</b>, <b>fbs</b>, restecg, <b>thalach</b>, <b>exang</b>, <b>oldpeak</b>, slope, <b>ca</b>, thal <br>\n",
    "    (in bold the non categorical ones) <br> <br>\n",
    "    \n",
    "    cp, restecg, slope and thal are categorical <br>\n",
    "    - <b>cp</b> has 4 different values, so it will become: cp1, cp2, cp3, cp4 <br>\n",
    "    - <b>restecg</b> has 3 different values, so it will become: restecg0, restecg1, restecg2 <br>\n",
    "    - <b>slope</b> has 3 different values, so it will become: slope1, slope2, slope3 <br>\n",
    "    - <b>thal</b> has 3 different values, so it will become: thal3, thal6, thal7 <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each feature, add the corresponding columns\n",
    "df = pd.concat([df, pd.get_dummies(df['cp'], prefix='cp')], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['restecg'], prefix='restecg')], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['slope'], prefix='slope')], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['thal'], prefix='thal')], axis=1)\n",
    "\n",
    "# Remove the \"old\" column\n",
    "df.drop(['cp'],axis=1, inplace=True)\n",
    "df.drop(['restecg'],axis=1, inplace=True)\n",
    "df.drop(['slope'],axis=1, inplace=True)\n",
    "df.drop(['thal'],axis=1, inplace=True)\n",
    "\n",
    "# Create a new column called presence representing the presence of heart disease \n",
    "df['presence'] = df['num'] > 0\n",
    "#df['presence'] = df['num'] \n",
    "df = df.astype({'presence': int})\n",
    "\n",
    "# Rearrange columns order\n",
    "df = df[['age', 'sex', 'trestbps', 'chol', 'fbs', 'thalach', 'exang', 'oldpeak',\n",
    "       'ca', 'cp_1', 'cp_2', 'cp_3', 'cp_4', 'restecg_0', 'restecg_1',\n",
    "       'restecg_2', 'slope_1', 'slope_2', 'slope_3', 'thal_3', 'thal_6',\n",
    "       'thal_7', 'num', 'presence']]\n",
    "\n",
    "# Function that, given a length of an array and a percentage p, \n",
    "# it will return p% of indexes of that array, randomly chosen, sorted\n",
    "def defineTraining (length, percentage=0.8):\n",
    "    sample = random.sample(range(0, length), int(percentage*length))\n",
    "    sample = np.sort(sample)\n",
    "    return sample\n",
    "\n",
    "# Function that:\n",
    "# - sample 80% of the data and select it as training set\n",
    "# - use training data to do cross validation (k=10)\n",
    "# - once it has the best parameters, train the model on the training set\n",
    "# - test results using test set and returns a percentage of right predictions\n",
    "def applyRandomForest():\n",
    "    # Pick 80% of data as training set\n",
    "    pickAsTraining = defineTraining(len(df), 0.8)\n",
    "    \n",
    "    # Add a column to our dataframe, default value will be 0\n",
    "    df['is_train'] = 0\n",
    "    \n",
    "    # For each element selected as training, set its value in 'is_train' to 1\n",
    "    for el in pickAsTraining :\n",
    "        df.loc[el,'is_train'] = 1\n",
    "    \n",
    "    # Split our dataset in test and train, depending on the value in 'is_train' column\n",
    "    test, train = df[df['is_train']==0], df[df['is_train']==1]\n",
    "    # Select the features that will be used for training (in order to not use the labels for training)\n",
    "    features = df.columns[:22] \n",
    "    \n",
    "    # Initialize our classifier\n",
    "    clf = RandomForestClassifier(n_jobs = -1, random_state=0)\n",
    "    \n",
    "    # Cross validation - BEGIN {\n",
    "    \n",
    "    # Create arrays in which I'll save the possible values of parameters to be used in RF   \n",
    "    n_estimators = [800, 1000, 1200]\n",
    "    max_depth = [60, 100, 140]\n",
    "    max_depth.append(None)\n",
    "    max_features = [2, 5, 11]\n",
    "    min_samples_leaf = [7, 10, 13]\n",
    "    min_samples_split = [2, 4, 6]\n",
    "    \n",
    "    # Create the random grid containing the possible parameters for RF\n",
    "    random_grid = {\n",
    "        'n_estimators': n_estimators,\n",
    "        'max_depth': max_depth,\n",
    "        'max_features': max_features,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'min_samples_split': min_samples_split\n",
    "    }\n",
    "    \n",
    "    # Define an object representing the CV method, already implemented, called on our classifier\n",
    "    grid_search = GridSearchCV(estimator = clf, param_grid = random_grid, cv = 10, n_jobs = -1, verbose = 1)\n",
    "    \n",
    "    # Call the CV model\n",
    "    grid_search.fit(train[features], train['presence'])\n",
    "      \n",
    "    # } Cross Validation - END\n",
    "    \n",
    "    # Redefine our classifier with the found parameters\n",
    "    clf = RandomForestClassifier(\n",
    "        n_jobs = -1,\n",
    "        random_state = 0,\n",
    "        n_estimators = grid_search.best_params_[\"n_estimators\"],\n",
    "        max_depth = grid_search.best_params_[\"max_depth\"],\n",
    "        max_features = grid_search.best_params_[\"max_features\"],\n",
    "        min_samples_leaf = grid_search.best_params_[\"min_samples_leaf\"],\n",
    "        min_samples_split = grid_search.best_params_[\"min_samples_split\"]\n",
    "    )\n",
    "    \n",
    "    clf.fit(train[features], train['presence'])\n",
    "    predictions = clf.predict(test[features])\n",
    "    matching = [predictions == test['presence'].values]\n",
    "    totalMatches = np.sum(matching) / len(predictions)\n",
    "    \n",
    "    return totalMatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call K times the function \"applyRandomForest()\"\n",
    "K = 20\n",
    "results = np.zeros(K)\n",
    "\n",
    "for i in range(0,K):\n",
    "    #if (i%(int)(K/10) == 0):\n",
    "    #    print ((int)(i/K*100), \"%\")\n",
    "    results[i] = applyRandomForest()\n",
    "\n",
    "#print(results)    \n",
    "print(np.average(results))\n",
    "print(np.std(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
